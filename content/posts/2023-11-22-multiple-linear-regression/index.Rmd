---
title: "Tree-based Regression"
author: "Oskar Mikko"
date: '2023-11-25'
slug: []
categories:
  - Machine Learning
tags:
  - R
  - CART
  - Regression
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE,warning=FALSE,message=F)
```

```{r}
library(tidyverse)
library(DAAG)
library(party)
library(rpart)
library(rpart.plot)
library(mlbench)
library(pROC)
library(tree)
library(caret)
```

# Decision trees

- The goal is to predict an outcome based on a set of predictors.

## Regression Tree: Predicting median value of Boston homes

```{r cars}
data('BostonHousing')
data <- BostonHousing
str(data)
```

The data contains 506 observations and 14 different variables:

- crim: per capita crime rate by town
- zn: proportion of residential land zoned for lots over 25,000 sq.ft
- indus: proportion of non-retail business acres per town
- chas: Charles River dummy varaible(1= if tract bounds river, 0 otherwise)
- nox: nitric oxides concentraion
- rm: averigare number of rooms per dwelling
- age: prortion of owner-occupied units built prior to 1940
- dis: weighted distances to five Boston employment centres
- rad: index of accessibility to radial highways
- tax: full-value property-tax rate per USD 10,000
- ptratio: pupil-teacher ratio by town
- b: $1000*(B-0.63)^2$ where B is the proportion of blacks by town
- lstat: percentage of lower status of the population
- medv: median value of owner-occupied homes in USD 1000's.

where medv is the predictor variable.

# Splitting data

First we need to split the data into training and testing data.

```{r}
set.seed(1337)
ind <- sample(2, nrow(mydata), replace = T, prob = c(0.5, 0.5))
train <- mydata[ind == 1,]
test <- mydata[ind == 2,]
```

# The tree  

```{r}
tree <- rpart(medv ~., data = train)
rpart.plot(tree)
```

```{r}
printcp(tree)
``` 

```{r}
plotcp(tree)
``` 

