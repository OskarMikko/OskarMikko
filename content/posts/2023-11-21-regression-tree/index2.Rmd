---
title: "Tree-based classification and regression"
author: "Oskar Vilhelmsson"
date: "2023-11-21"
output: pdf_document
categories: Machine Learning
tags:
- R
- Classification
- CART
- Regression
slug: []
---

```{r setup, include=FALSE,}
knitr::opts_chunk$set(collapse = TRUE,warning=FALSE,message=F)
```

# Decision trees

- The goal is to classify or predict an outcome based on a set of predictors.

```{r}
library(tidyverse)
library(DAAG)
library(party)
library(rpart)
library(rpart.plot)
library(mlbench)
library(pROC)
library(tree)
library(caret)
```

## Classification Tree: Detecting email spam data


```{r}
data <- spam7
str(data)  
table(data$yesno)
```

The data consists of 4601 emails, 1813 of them were considered as spam emails.

The variables in the dataset are:
 - crl.tot: total length of words in capitals
 - dollar: number of occurrences of the $ symbol.
 - bang: number of occurrences of the ! symbol.
 - money: number of occurrences of the word 'money'
 - n000: number of occurrences of the string '000'
 - make: number of occurrences of the word 'make'
 - yesno: outcome variable; y = if spam, no = if not spam

- The goal is to classify each email as spam or not spam using the decision tree.

# Splitting data

We need to split data into training and testing for our model. 

```{r}
set.seed(1337)
index <- sample(2, nrow(data), replace = T, prob = c(0.5, 0.5))
train <- data[index == 1,]
test <- data[index == 2,]
``` 

# The tree  
```{r}
tree <- rpart(yesno ~., data = train)
rpart.plot(tree)
```
The root node is dollar and if dollar is > 0.046 then the email is classified as spam. 27% of the data has dollar > 0.046 and 88% of that data is spam.

The second node is bang, and the splitting criteria is bang < 0.18. 



```{r}
printcp(tree)
plotcp(tree)
```




